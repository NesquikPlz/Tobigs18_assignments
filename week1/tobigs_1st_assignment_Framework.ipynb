{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt1H5o-poBfF"
      },
      "source": [
        "# 1. 라이브러리 import 및 GPU 할당\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B1X8mpttn-Vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf5081b-45c4-4972-bdd2-f1e409b067b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is available\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transfroms\n",
        " \n",
        " #GPU 사용 가능 여부를 확인하고있다.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "print(device + \" is available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 하이퍼파라미터 설정"
      ],
      "metadata": {
        "id": "FdWW5gNAliQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate : gradient의 방향으로 얼마나 빠르게 이동할 것인지 결정\n",
        "# batch size : 전체 학습 데이터를 등분하는 크기\n",
        "# num classes : y(class)의 개수\n",
        "# epoch : 반복 학습 횟수\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "num_classes = 10\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "zLAoxXCRlhsJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWzCD1LRn-vT"
      },
      "source": [
        "# 3. training 및 test 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7YfkyOQioSBj"
      },
      "outputs": [],
      "source": [
        "train_set = torchvision.datasets.MNIST( #torchvision이 제공하는 데이터셋\n",
        "    root = './data/MNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transfroms.Compose([ #numpy 이미지에서 torch이미지로 변경한다.(축변환)\n",
        "        transfroms.ToTensor() \n",
        "    ])\n",
        ")\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transfroms.Compose([\n",
        "        transfroms.ToTensor()\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. 학습용 데이터 준비하기"
      ],
      "metadata": {
        "id": "rH0jiUknl6jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터로더는 샘플들을 미니배치로 전달하고, 메 에포크마다 데이터를 다시 섞어 과적합을 방지한다.\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "#enumerate 함수는 기본적으로 index와 원소로 이루어진 tuple을 만들어준다.\n",
        "examples = enumerate(train_set)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YPEEhmel6vb",
        "outputId": "9a4b4b57-500c-4efd-f81e-f843a3ad33f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ_MTPYyoUbo"
      },
      "source": [
        "# 5. 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LQee8cNioUjL"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self): \n",
        "        super(ConvNet, self).__init__() # super class로 지금 작성하고 있는 클래스를 초기화\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # 입력채널 수 = 1, 출력 채널 수 = 10, kernel size = 5, stribe = 1, ? = 0 인 convolution layer이다\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
        "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) # dropout 비율이 0.25인 droupout layer. 오버피팅을 방지하기 위한\n",
        "        self.mp = nn.MaxPool2d(2) # 합성곱 연산. 필터크기 2*2\n",
        "        self.fc1 = nn.Linear(320,100) #입력 차원 320 출력차원 100의 linear layer\n",
        "        self.fc2 = nn.Linear(100,10) \n",
        "\n",
        "  def forward(self, x):\n",
        "        x = F.relu(self.mp(self.conv1(x))) #activate 함수가 relu로 conv - maxpool - relu 의 순서\n",
        "        x = F.relu(self.mp(self.conv2(x))) \n",
        "        x = self.drop2D(x)\n",
        "        x = x.view(x.size(0), -1) #데이터를 1차원 형태로 변환한다.\n",
        "        x = self.fc1(x) #fully connected layer로 classification을 위해 추가\n",
        "        x = self.fc2(x) \n",
        "        return F.log_softmax(x) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDVGW05NoUri"
      },
      "source": [
        "# 6. loss 함수 및 optimizer 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Hn6FU1proUxO"
      },
      "outputs": [],
      "source": [
        "model = ConvNet().to(device) \n",
        "criterion = nn.CrossEntropyLoss().to(device) #loss함수는 cross entropy loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) #optimization 함수는 adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35KJ9PP9oVCI"
      },
      "source": [
        "# 7. training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_aJMrF54oVGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f202eb-2ff3-44b5-83a3-25cd9367ee20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.0389175154\n",
            "[Epoch:    2] cost = 0.0326781794\n",
            "[Epoch:    3] cost = 0.0284960065\n",
            "[Epoch:    4] cost = 0.0243383907\n",
            "[Epoch:    5] cost = 0.0211132523\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs): \n",
        "    avg_cost = 0\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        # 모든 model의 gradient 값을 0으로 설정\n",
        "        # 초기화 이유 : 기울기를 초기화해야만 새로운 가중치 편향에 대해 기울기를 구할 수 있다\n",
        "        hypothesis = model(data)\n",
        "        cost = criterion(hypothesis, target) # 모델의 결과와 target를 비고해 loss를 구한다\n",
        "        cost.backward() # 역전파 시행\n",
        "        optimizer.step() \n",
        "        avg_cost += cost / len(train_loader) \n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. validation"
      ],
      "metadata": {
        "id": "wI8jka41qTkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad(): # gradient를 계산해주는 engine을 비활성화시켜 필요한 메모리를 줄이고 속도를 증가시킨다.\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        out = model(data)\n",
        "        preds = torch.max(out.data, 1)[1] \n",
        "        total += len(target) \n",
        "        correct += (preds==target).sum().item() \n",
        "        \n",
        "    print('Test Accuracy: ', 100.*correct/total, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or_2lE-SqTrb",
        "outputId": "11d406e6-b30c-4585-a653-ffc6c286e0a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  98.8 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Framework_PyTorch.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}